{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758d3553-31b8-4222-bbaa-2ddad903b959",
   "metadata": {},
   "source": [
    "# Differentiable Intonation Tools Examples\n",
    "This notebook shows the usage of the Differentiable Intonation Tools (`dit`) with a simple example. We first synthesize some audio signals of voices with randomly varying tuning, then visualize the two intonation costs `dit.cost.tonal` and `dit.cost.harmonic`, and finally calculate and apply pitch-shift curves that minimize the cost.\n",
    "\n",
    "Contributors: Simon Schwär, Sebastian Rosenzweig, Meinard Müller<br>\n",
    "License: [The MIT license](https://opensource.org/licenses/MIT)\n",
    "\n",
    "This file is part of the [Differentiable Intonation Tools](https://github.com/simonschwaer/differentiable-intonation-tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60356c8b-e1a8-4538-94b2-977da012c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dit\n",
    "import libtsm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9aa66-3d57-4bb4-ad42-f8b9e991ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global settings\n",
    "\n",
    "fs = 32000.\n",
    "voices = ['S', 'A', 'T', 'B']\n",
    "\n",
    "total_duration = 8. # seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474eca5f-a1e1-44a4-8762-ac072bff1cb3",
   "metadata": {},
   "source": [
    "### Step 1: Generate random \"detuning curves\" for all voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832c7e21-9a27-42d2-8ef4-8f6749cdc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "dt = 0.1 # step size in seconds\n",
    "win_size = 10 # smoothing window for random detuning\n",
    "\n",
    "detune = {}\n",
    "\n",
    "num_frames = int(total_duration/dt)+1\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "t = np.linspace(0, total_duration, num_frames)\n",
    "\n",
    "for voice in voices:\n",
    "    y = np.cumsum(np.random.rand(num_frames) * 16 - 9) # slightly favoring downwards\n",
    "    detune[voice] = np.convolve(\n",
    "        np.pad(y, (int(win_size/2)-1, int(win_size/2)), 'edge'),\n",
    "        np.hamming(win_size)/win_size,\n",
    "        mode='valid'\n",
    "    )\n",
    "\n",
    "    plt.plot(t, detune[voice], label=\"Voice %s\" % voice)\n",
    "\n",
    "plt.title(\"Randomly generated detuning for all voices\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Detuning [cents]\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc087cf-8991-4b7e-b840-c7f628d441d5",
   "metadata": {},
   "source": [
    "### Step 2: Synthesize audio with the detuning curves above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63274ef5-0d6a-4bd1-a6a3-daa5362bf711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_voice_detuned(tones, duration, dt, fs, curve, **kwargs):\n",
    "    result = np.zeros((int(duration*fs)))\n",
    "    i = 0\n",
    "    t = 0.\n",
    "    j = 0\n",
    "    for tone in tones:\n",
    "        l = int(tone[0] * fs)\n",
    "        win = np.ones((l))\n",
    "        win[:100] = np.sin(np.linspace(0, np.pi/2, 100))\n",
    "        win[-100:] = np.cos(np.linspace(0, np.pi/2, 100))\n",
    "        sig = np.zeros((l))\n",
    "        carry = []\n",
    "        i1 = 0\n",
    "        for t1 in np.arange(t, t+tone[0], dt):\n",
    "            l1 = int(dt * fs)\n",
    "            sig[i1:i1+l1], carry = dit.utils.synth(\n",
    "                dit.utils.s2f(tone[1]) * np.power(2, curve[j]/1200),\n",
    "                dt, fs=fs, init_phase=carry, **kwargs\n",
    "            )\n",
    "            i1 += l1\n",
    "            j += 1\n",
    "        result[i:i+l] += win * sig\n",
    "        i += l\n",
    "        t += tone[0]\n",
    "    return result\n",
    "\n",
    "d = total_duration/4\n",
    "sheet_music = {\n",
    "    'S': [(d, \"A4\"), (d, \"A4\"), (d, \"A4\"), (d, \"G4\")],\n",
    "    'A': [(d, \"F4\"), (d, \"E4\"), (d, \"Eb4\"), (d, \"D4\")],\n",
    "    'T': [(d, \"C4\"), (d, \"C4\"), (d, \"C4\"), (d, \"Bb3\")],\n",
    "    'B': [(d, \"F3\"), (d, \"A3\"), (d, \"F#3\"), (d, \"G3\")],\n",
    "}\n",
    "\n",
    "x = {}\n",
    "x_mix = np.zeros((int(total_duration*fs)))\n",
    "for voice in voices:\n",
    "    x[voice] = 0.5 * synth_voice_detuned(sheet_music[voice], total_duration, dt, fs, detune[voice])\n",
    "    x_mix += x[voice]\n",
    "\n",
    "ipd.display(ipd.Audio(x_mix, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc831d-1ce0-4594-b6fb-daeda7c46219",
   "metadata": {},
   "source": [
    "### Step 3: Calculate peaks for each voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce4c6a7-982c-4cee-b689-101938e7e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings for analysis\n",
    "frame_length = int(dt * fs) # in samples\n",
    "fft_size = 4096 # in samples\n",
    "adapt_rate = 350 # 350 # # in samples\n",
    "\n",
    "# settings for peak detection\n",
    "filter_len = 10 # in samples, window size for harmonic-percussive separation\n",
    "freq_lim = 8000 # in Hz, highest possible frequency of a peak\n",
    "peak_threshold = 0 # in dB, minimum peak level\n",
    "peak_prominence = 10 # in dB, minimum difference between peak and its surrounding\n",
    "peak_distance = 1 # in bins, minimum distance between peaks\n",
    "max_peaks = 16\n",
    "\n",
    "\n",
    "P = []\n",
    "\n",
    "for voice in voices:\n",
    "    print(\"Finding peaks for %s...\" % voice)\n",
    "    t_P, peaks, _ = dit.utils.find_peaks(x[voice], fs, fft_size, frame_length, max_peaks, filter_len, freq_lim,\n",
    "                                         height=peak_threshold, distance=peak_distance, prominence=peak_prominence)\n",
    "    P.append(peaks)\n",
    "    \n",
    "P = np.array(P)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb958bb4-0812-42f5-b950-ddee8edafb30",
   "metadata": {},
   "source": [
    "### Step 4: Calculate tonal cost heatmap\n",
    "This shows in a heatmap, which pitch-shifts result in a lower tonal cost. For this, we virtually pitch-shift the peaks of interest by -100 to 100 cents and calculate the tonal cost (`dit.cost.tonal`) for each shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d60ff1-b5ea-4c49-96c4-93d1784872c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = P.shape[1] # number of time frames\n",
    "M = P.shape[2] # number of frequencies per voice\n",
    "N = 100 # resolution of the cost calculation\n",
    "v = voices.index('S') # voice of interest\n",
    "\n",
    "cents = np.linspace(-100, 100, N)\n",
    "factors = np.power(2, cents/1200)\n",
    "\n",
    "P_lead = P[v]\n",
    "# accumulate all other voices in a single set\n",
    "backing_voices = []\n",
    "for i in range(len(voices)):\n",
    "    if i == v: continue\n",
    "    backing_voices.append(P[i])\n",
    "P_backing = np.concatenate(backing_voices, axis=1)\n",
    "\n",
    "result = np.zeros((L, N))\n",
    "\n",
    "for n in range(N):\n",
    "    P_test = P_lead.copy()\n",
    "    P_test[:,:,0] *= factors[n]\n",
    "\n",
    "    result[:,n] = dit.cost.tonal_for_frames(P_test, P_backing, fit_grid=False, f_ref=440., gradient=False)\n",
    "\n",
    "plt.figure(figsize=(10,5), tight_layout=True)\n",
    "plt.pcolormesh(t_P, cents, result.T, vmin=0, vmax=1, cmap=\"magma\", shading=\"auto\")\n",
    "\n",
    "plt.title(\"Tonal cost landscape for voice %s\" % voices[v])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Pitch-shift [cents]\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cbde0e-1a8c-4fbf-bfcd-65a62da1fbbf",
   "metadata": {},
   "source": [
    "### Step 5: Calculate harmonic cost heatmap\n",
    "This shows in a heatmap, which pitch-shifts result in a lower harmonic cost. For this, we virtually pitch-shift the peaks of interest by -100 to 100 cents and calculate the tonal cost (`dit.cost.harmonic`) w.r.t. all other voices for each shift.\n",
    "\n",
    "Note: this may take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6616c2b-6427-4e70-a51e-3b722c39cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = P.shape[1] # number of time frames\n",
    "M = P.shape[2] # number of frequencies per voice\n",
    "N = 100 # resolution of the cost calculation\n",
    "v = voices.index('S') # voice of interest\n",
    "\n",
    "cents = np.linspace(-100, 100, N)\n",
    "factors = np.power(2, cents/1200)\n",
    "\n",
    "P_lead = P[v]\n",
    "# accumulate all other voices in a single set\n",
    "backing_voices = []\n",
    "for i in range(len(voices)):\n",
    "    if i == v: continue\n",
    "    backing_voices.append(P[i])\n",
    "P_backing = np.concatenate(backing_voices, axis=1)\n",
    "\n",
    "result = np.zeros((L, N))\n",
    "for n in range(N):\n",
    "    P_test = P_lead.copy()\n",
    "    P_test[:,:,0] *= factors[n]\n",
    "\n",
    "    result[:,n] = dit.cost.harmonic_for_frames(P_test, P_backing, fixed_wc=0.03, gradient=False)\n",
    "\n",
    "plt.figure(figsize=(10,5), tight_layout=True)\n",
    "plt.pcolormesh(t_P, cents, result.T, vmin=0, vmax=1, cmap=\"magma\", shading=\"auto\")\n",
    "\n",
    "plt.title(\"Harmonic cost landscape for voice %s\" % voices[v])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Pitch-shift [cents]\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf7edc-0dc2-44f1-a6ff-2536ed63445c",
   "metadata": {},
   "source": [
    "### Step 6: Run joint gradient descent\n",
    "Calculate a pitch-shift curve for each voice to minimize the cost at each time step. You can play with different parameters for `shifts_a` and `shifts_b` to see, how they change the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932f65b-2b80-4026-9453-0e5239997d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_a = dit.analysis.calc_shifts_multivoice(P, wt=0.33, wh=0.67, mu=450)\n",
    "shifts_b = dit.analysis.calc_shifts_multivoice(P, wt=1., wh=0., mu=450)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "\n",
    "t = np.arange(0, shifts_a.shape[1]) * dt\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "for i in range(len(shifts_a)):\n",
    "    plt.plot(t, shifts_a[i], color=colors[i], label=\"Voice %s\" % voices[i])\n",
    "    plt.plot(t, shifts_b[i], color=colors[i], linestyle=\"--\")\n",
    "\n",
    "plt.title(\"Pitch shift curves from joint gradient descent (solid: wt=0.33, dashed: wt=1)\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Pitch-shift [cents]\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1b13e-2854-425c-94dc-4e3d18b5752f",
   "metadata": {},
   "source": [
    "### Step 7: Apply pitch-shift curves to signals\n",
    "Pitch-shift the signals with curves from above using adaptive pitch-shifting from `libtsm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70447c4d-c0a9-43cc-ba2c-e7b57e7e4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = {}\n",
    "y_mix = np.zeros((int(total_duration*fs)))\n",
    "for voice in voices:\n",
    "    y[voice] = libtsm.pitch_shift(x[voice], shifts_a[voices.index(voice)], t)[:,0]\n",
    "    y_mix += y[voice]\n",
    "\n",
    "print(\"Original:\")\n",
    "ipd.display(ipd.Audio(x_mix, rate=fs))\n",
    "print(\"Pitch-shifted:\")\n",
    "ipd.display(ipd.Audio(y_mix, rate=fs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
